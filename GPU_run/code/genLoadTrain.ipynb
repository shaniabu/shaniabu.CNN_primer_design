{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb64d0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "data set (400,)\n",
      "vectorSize 29903\n",
      "340\n",
      "29726\n",
      "(340,)\n",
      "20\n",
      "(20,)\n",
      "40\n",
      "(40,)\n",
      "4\n",
      "340\n",
      "4\n",
      "(340, 4)\n",
      "20\n",
      "4\n",
      "(20, 4)\n",
      "40\n",
      "4\n",
      "(40, 4)\n",
      "8\n",
      "INFO:tensorflow:Restoring parameters from ../data/model/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 06:46:14.043742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22852 MB memory:  -> device: 0, name: TITAN RTX, pci bus id: 0000:b1:00.0, compute capability: 7.5\n",
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/client/session.py:1766: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 29903, 1)\n",
      "(?, 1, 203, 12)\n",
      "(?, 4)\n",
      "(?, 4)\n",
      "test  20\n",
      "[1.   0.75 1.   ... 0.   0.   0.  ]\n",
      "[0. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 06:46:15.190714: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2023-02-14 06:46:15.677953: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-14 06:46:15.679950: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-14 06:46:15.680067: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2023-02-14 06:46:15.681486: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-14 06:46:15.681767: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899999996026357\n",
      "0\t0\t0.3\t0.3\t0.1\t0.35\t1.36996\t1.4154\n",
      "0.799999992052714\n",
      "1\t0\t0.325\t0.3\t0.2\t0.35\t1.34522\t1.35289\n",
      "0.6166666547457378\n",
      "2\t0\t0.475\t0.55\t0.383333\t0.5\t1.35831\t1.36262\n",
      "0.6166666547457378\n",
      "3\t0\t0.4\t0.3\t0.383333\t0.35\t1.34752\t1.30466\n",
      "0.6333333253860474\n",
      "4\t0\t0.15\t0.25\t0.366667\t0.275\t1.34132\t1.37637\n",
      "0.7333333293596904\n",
      "5\t0\t0.2\t0.25\t0.266667\t0.275\t1.32843\t1.34822\n",
      "0.6666666666666667\n",
      "6\t0\t0.45\t0.5\t0.333333\t0.45\t1.33317\t1.30911\n",
      "0.6000000039736431\n",
      "7\t0\t0.425\t0.45\t0.4\t0.5\t1.31134\t1.31153\n",
      "0.450000007947286\n",
      "8\t0\t0.6\t0.7\t0.55\t0.775\t1.30005\t1.32108\n",
      "9\t0\t0.425\t0.45\t0.55\t0.775\t1.31019\t1.29706\n",
      "0.450000007947286\n",
      "(40, 1, 29903, 12)\n",
      "(40, 1, 203, 12)\n"
     ]
    }
   ],
   "source": [
    "#Declarations******************************************************************************\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "from funcCNN import *\n",
    "from crossValB import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataFolder='../data/'\n",
    "\n",
    "#Output:\n",
    "f=open(dataFolder+'results/outputVector.txt', 'w')\n",
    "f.write('1\\n')\n",
    "f.write('1\\n')\n",
    "temp=1.0\n",
    "trueAcc=str(temp)\n",
    "print(trueAcc)\n",
    "f.write(trueAcc+'\\n')\n",
    "f.close()\n",
    "#Parameters*******************************************************************************\n",
    "#Maximum number of iterations\n",
    "#iterMax=int(sys.argv[1])\n",
    "iterMax=10\n",
    "#maximum number of iterations\n",
    "limit=1.01\n",
    "#regularization on the weights\n",
    "beta=0.001\n",
    "#version of the code\n",
    "version='gen1'\n",
    "#size of batch\n",
    "batchSize=40\n",
    "#Parameters*******************************************************************************\n",
    "#w1=int(sys.argv[2]) #12\n",
    "#w4=int(sys.argv[3]) #196\n",
    "#h1=int(sys.argv[4]) #148\n",
    "#wd1=int(sys.argv[5]) #21\n",
    "#index=int(sys.argv[6]) #0\n",
    "#kfoldIndex=int(sys.argv[7]) #0\n",
    "#generation=int(sys.argv[8]) #0\n",
    "\n",
    "w1=12\n",
    "w4=196\n",
    "h1=148\n",
    "wd1=21\n",
    "index=0\n",
    "kfoldIndex=0\n",
    "generation=0\n",
    "#Input Data***********************************************************************************\n",
    "(test_dataset_Flat,oneHot_test_labels,valid_dataset_Flat,oneHot_valid_labels,\n",
    "\ttrain_dataset_Flat,oneHot_train_labels,labelSize,vectorSize)=get_Info(\n",
    "\tkfoldIndex,dataFolder)\n",
    "runs=int(len(oneHot_train_labels)/batchSize)\n",
    "print(runs)\n",
    "#Model declaration************************************************************************\n",
    "#import tensorflow as tf\n",
    "#declare interactive session\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "sess=tf.InteractiveSession()\n",
    "\n",
    "\n",
    "#INPUT->CONV LAYER->CONV LAYER->CONV LAYER->RECT FLAT->RECT DROPOUT\n",
    "\n",
    "#function to declare easily the weights only by shape\n",
    "def weight_variable(shape):\n",
    "\tinitial = tf.truncated_normal(shape, stddev=0.1)\n",
    "\treturn tf.Variable(initial)\n",
    "#function to declare easily the bias only by shape\n",
    "def bias_variable(shape):\n",
    "\tinitial = tf.constant(0.1, shape=shape)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "#input variable\n",
    "x = tf.placeholder(tf.float32, [None, vectorSize])\n",
    "#keep probability to change from dropout 0.50 to 1.0 in validation and test\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "#expected outputs variable\n",
    "y_ = tf.placeholder(tf.float32, [None, labelSize])\n",
    "\n",
    "#arrange the tensor as an image (1*31029) 1 channel\n",
    "x_image0 = tf.reshape(x, [-1,1,vectorSize,1])\n",
    "x_image = tf.transpose(x_image0, perm=[0,3,2,1])\n",
    "#arrange the tensor into 1 channels (1*31029)\n",
    "\n",
    "#1 LAYER*************************************************************************************\n",
    "#1 Convolutional Layer Explicit for regularization of the weights\n",
    "#weigth first layer 1 input channels, 12 output channels, 1x21 filter window size\n",
    "W_conv1 = weight_variable([1, wd1, 1, w1])\n",
    "#bias declaration the size has to be the same as the output channels 12\n",
    "b_conv1 = bias_variable([w1])\n",
    "#convolution (input weights) moving 1 step each time with a relu\n",
    "h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, \n",
    "\tstrides=[1, 1, 1, 1], padding='SAME') + b_conv1)\n",
    "#max pooling with a 148 width window size, moving 148 in width by step\n",
    "h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 1, h1, 1],\n",
    "\tstrides=[1, 1, h1, 1], padding='SAME')\n",
    "#output=545/4\n",
    "#1 LAYER*************************************************************************************\n",
    "\n",
    "#Rectifier LAYER*****************************************************************************\n",
    "#calculated coefficient for the flattening from the size of the 3 convolutional layer\n",
    "coef=int (h_pool1.get_shape()[1]*h_pool1.get_shape()[2]*h_pool1.get_shape()[3])\n",
    "h_pool2_flat = tf.reshape(h_pool1, [-1, coef])\n",
    "#declare the weights considering the constants and 256 output \n",
    "W_fc1 = weight_variable([coef, w4])\n",
    "b_fc1 = bias_variable([w4])\n",
    "\n",
    "#rectifier (matmul)\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "#Rectifier LAYER*****************************************************************************\n",
    "\n",
    "#Rectifier-Dropout LAYER**********************************************************************\n",
    "#dropout\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "#declare weights with the ouput layer in this case 2 (labelSize)\n",
    "W_fc2 = weight_variable([w4, labelSize])\n",
    "b_fc2 = bias_variable([labelSize])\n",
    "#output\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "#Rectifier-Dropout LAYER**********************************************************************\n",
    "\n",
    "#Loss Function********************************************************************************\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[0]))\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_conv, labels=y_)+\n",
    "\tbeta*tf.nn.l2_loss(W_conv1))\n",
    "#Optimizer Adam at 1e-5 (literature)**********************************************************\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "#softmax prediction remember we are using one hot labels\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "\n",
    "trueResult=tf.argmax(y_conv,1)\n",
    "trueTest=tf.argmax(y_,1)\n",
    "#accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#Loss Function********************************************************************************\n",
    "valid_accuracy_global=0.0\n",
    "test_accuracy_global=0.0\n",
    "\n",
    "#start\n",
    "sess.run(tf.initialize_all_variables())\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"../data/model/model.ckpt\")\n",
    "#Extra to verify sizes************************************************************************\n",
    "print(x_image.get_shape())\n",
    "#print(h_conv1.get_shape())\n",
    "print(h_pool1.get_shape())\n",
    "\n",
    "print(y_conv.get_shape())\n",
    "print(y_.get_shape())\n",
    "#Extra to verify sizes************************************************************************\n",
    "\n",
    "print('test ',str(oneHot_valid_labels.shape[0]))\n",
    "\n",
    "xaV,yaV=getBatch(valid_dataset_Flat,oneHot_valid_labels,oneHot_valid_labels.shape[0],vectorSize)\n",
    "print(xaV[1])\n",
    "print(yaV[1])\n",
    "\n",
    "yResult=[]\n",
    "yTest=[]\n",
    "#Ouput Data Variables*************************************************************************\n",
    "name=str(str(kfoldIndex)+'_'+str(iterMax)+'_'+str(w1)+'_'+str(w4)+'_'+str(h1)+'_'+str(wd1))\n",
    "f = open(dataFolder+'results/'+name+'.txt', 'a')\n",
    "#Ouput Data Variables*************************************************************************\n",
    "\n",
    "#Main Loop************************************************************************************\n",
    "#initialize variables\n",
    "iter=0\n",
    "train_accuracy=0.0\n",
    "valid_accuracy=0.0\n",
    "test_accuracy=0.0\n",
    "#best validation accuracy\n",
    "best=0\n",
    "validWindow=[0,0,0]\n",
    "repeatWindow=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "validBest=1e6\n",
    "#limit (normally a dummy value 0.80) and iterations...\n",
    "while ((best<limit) & (iter<iterMax)):\n",
    "\tindexBatch=[]\n",
    "\tfor iB in range (0,len(oneHot_train_labels)):\n",
    "\t\tindexBatch.append(iB)\n",
    "\trandom.shuffle(indexBatch)\n",
    "\tfor run in range (0,runs):\n",
    "\t\t#Get data from train set and store in xa (inputs),ya(labels),ca(constants) 100 batch size\n",
    "\t\txa,ya=getBatch_run(train_dataset_Flat,oneHot_train_labels,batchSize,run,indexBatch,vectorSize)\n",
    "\t\t#pass the values and 0.50 dropout (literature)\n",
    "\t\ttrain_step.run(feed_dict={x: xa, y_: ya, keep_prob: 0.5})\n",
    "\t\t#print each 10 iterations\n",
    "\t#calculate train accuracy\n",
    "\txa,ya=getBatch(train_dataset_Flat,oneHot_train_labels,batchSize,vectorSize)\n",
    "\ttrain_accuracy = accuracy.eval(feed_dict={\n",
    "\t\tx:xa, y_: ya, keep_prob: 1.0})\n",
    "\t#calculate validation accuracy\n",
    "\txaV,yaV=getBatch(valid_dataset_Flat,oneHot_valid_labels,oneHot_valid_labels.shape[0],vectorSize)\n",
    "\t\n",
    "\tvalid_accuracy=accuracy.eval(feed_dict={\n",
    "\t\tx: xaV, y_: yaV, keep_prob: 1.0})\n",
    "\t#calculate validation loss\n",
    "\tcross_entropyVal=cross_entropy.eval(feed_dict={\n",
    "\t\tx: xaV, y_: yaV, keep_prob: 1.0})\n",
    "\t#calculate train loss\n",
    "\tcross_entropyTrain=cross_entropy.eval(feed_dict={\n",
    "\t\tx: xa, y_: ya, keep_prob: 1.0})\n",
    "\t#append values for graphs\n",
    "\t#if valid accuracy is better than the best accuracy then calculate test accuracy\n",
    "\t#if valid_accuracy>best:\n",
    "\tvalidWindowValue=0\n",
    "\ttempValid=validWindow\n",
    "\tfor i in range(0,len(validWindow)-1):\n",
    "\t\ttempValid[i]=validWindow[i+1]\n",
    "\tfor i in range(0,len(validWindow)):\n",
    "\t\tvalidWindow[i]=tempValid[i]\n",
    "\tvalidWindow[len(validWindow)-1]=valid_accuracy\n",
    "\tfor i in range(0,len(validWindow)):\n",
    "\t\tvalidWindowValue=validWindowValue+validWindow[i]\n",
    "\tvalidWindowValue=validWindowValue/len(validWindow)\n",
    "\ttempValid=repeatWindow\n",
    "\tfor i in range(0,len(repeatWindow)-1):\n",
    "\t\ttempValid[i]=repeatWindow[i+1]\n",
    "\tfor i in range(0,len(repeatWindow)):\n",
    "\t\trepeatWindow[i]=tempValid[i]\n",
    "\trepeatWindow[len(repeatWindow)-1]=valid_accuracy\n",
    "\tif np.var(repeatWindow)==0 and iter>10:\n",
    "\t\titer=iter\n",
    "\tif (validWindowValue)>best or cross_entropyVal<validBest:\n",
    "\t\tvalidBest=cross_entropyVal\n",
    "\t\tbest=(validWindowValue)\n",
    "\t\t\n",
    "\t\txaT,yaT=getBatch(test_dataset_Flat,oneHot_test_labels,oneHot_test_labels.shape[0],vectorSize)\n",
    "\t\t#calculate test accuracy\n",
    "\t\ttest_accuracy= accuracy.eval(feed_dict={x:xaT, \n",
    "\t\t\ty_: yaT, keep_prob: 1.0})\n",
    "\t\t# Save the variables to disk.\n",
    "\t\tif (kfoldIndex==0):\n",
    "\t\t\tsave_path = saver.save(sess, dataFolder+\"model/model.ckpt\")\n",
    "\t\t#plotNNFilter(units)\n",
    "\t\t#calculate the results of the whole model, probabilities in one hot format\n",
    "\t\tresults=correct_prediction.eval(feed_dict={x:xaT, y_: yaT, keep_prob: 1.0})\n",
    "\t\tyResult=trueResult.eval(feed_dict={x:xaT, y_: yaT, keep_prob: 1.0})\n",
    "\t\tyTest=trueTest.eval(feed_dict={x:xaT, y_: yaT, keep_prob: 1.0})\n",
    "\t\tfOut=open(dataFolder+'results/outputVector.txt', 'w')\n",
    "\t\tfOut.write('1\\n')\n",
    "\t\tfOut.write('1\\n')\n",
    "\t\ttemp=1.0-best\n",
    "\t\ttrueAcc=str(temp)\n",
    "\t\tprint(trueAcc)\n",
    "\t\tfOut.write(trueAcc+'\\n')\n",
    "\t\tfOut.close()\t\t\t\t\n",
    "\t#append everything to a log for retrieving results\n",
    "\tlog=\"%d\t%d\t%g\t%g\t%g\t%g\t%g\t%g\"%(iter,kfoldIndex,train_accuracy,valid_accuracy,best,\n",
    "\t\ttest_accuracy,cross_entropyVal,cross_entropyTrain)\n",
    "\tprint(log)\n",
    "\tf.write(log+'\\n')\n",
    "\titer=iter+1\n",
    "#Main Loop************************************************************************************\n",
    "\n",
    "f.close()\n",
    "saveVectorInt(dataFolder+'results/results'+name+'.txt',yResult)\n",
    "saveVectorInt(dataFolder+'results/test'+name+'.txt',yTest)\n",
    "f = open(dataFolder+'log3.txt', 'a')\n",
    "name=str(str(index)+'_'+str(kfoldIndex)+'_'+str(iterMax)+'_'+str(test_accuracy)+'_'+str(valid_accuracy)+'_'+str(best)+'_'+str(w1)+'_'+\n",
    "\t\t str(w4)+'_'+str(h1)+'_'+str(wd1)+'_'+str(generation))\n",
    "f.write(name+'\\n')\n",
    "f.close()\n",
    "\n",
    "#f=open(str(index)+'.index','a')\n",
    "#name=str(str(index)+'_'+str(kfoldIndex)+'_'+str(iterMax)+'_'+str(test_accuracy)+'_'+str(valid_accuracy)+'_'+str(best)+'_'+str(w1)+'_'+#\n",
    "#\t\t str(w4)+'_'+str(h1)+'_'+str(wd1)+'_'+str(generation))\n",
    "#f.write(name+'\\n')\n",
    "#f.close()\n",
    "#Input Data***********************************************************************************\n",
    "#close session\n",
    "f=open(dataFolder+'results/outputVector.txt', 'w')\n",
    "f.write('1\\n')\n",
    "f.write('1\\n')\n",
    "temp=1.0-best\n",
    "trueAcc=str(temp)\n",
    "print(trueAcc)\n",
    "f.write(trueAcc+'\\n')\n",
    "f.close()\n",
    "\n",
    "xaT,yaT=getBatch(test_dataset_Flat,oneHot_test_labels,oneHot_test_labels.shape[0],vectorSize)\n",
    "\n",
    "units = sess.run(h_conv1,feed_dict={x:xaT, \n",
    "\t\t\ty_: yaT, keep_prob: 1.0})\n",
    "print(units.shape)\n",
    "units = sess.run(h_pool1,feed_dict={x:xaT, \n",
    "\t\t\ty_: yaT, keep_prob: 1.0})\n",
    "print(units.shape)\n",
    "\n",
    "sess.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b83f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
